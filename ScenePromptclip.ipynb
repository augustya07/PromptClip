{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But first, let's install the dependecies.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from video_prompter import get_connection\n",
    "\n",
    "# TODO: setup .env file\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# connect to VideoDB\n",
    "conn = get_connection()\n",
    "\n",
    "### ----- Upload a fresh video --------- #####\n",
    "def fresh_video(url):\n",
    "    video = conn.upload(url=url)\n",
    "    #index spoken content in the video\n",
    "    video.index_spoken_words()\n",
    "    return video\n",
    "\n",
    "#### ------ run the prompt on video --------####\n",
    "def videodb_prompter(video_id, prompt):\n",
    "    video = get_video(video_id)\n",
    "    #get all the segment of videos that are\n",
    "    return video_prompter(video, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/71ad9a7c-6b05-46f8-8248-ed314cc94e9f.m3u8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "# ----Existing video case ----\n",
    "\n",
    "# TODO: replace with your video id\n",
    "# # video_id = \"m-replace-with-your-video-id-24-7\"\n",
    "# video_id = 'm-beb3ee4a-3169-4cb6-8dc1-beee73eb00a1'\n",
    "# video_id = 'm-beb3ee4a-3169-4cb6-8dc1-beee73eb00a1'\n",
    "video_id = \"m-2c2b792f-424c-432b-bcbe-9e3c7e00dcbf\"\n",
    "\n",
    "\n",
    "# ---- Fresh video case ----\n",
    "# url = \"https://youtu.be/pAMy7IhOVQE?si=6HMxVGP13hAHtmW3\"\n",
    "# video = fresh_video(url)\n",
    "# video_id = video.id\n",
    "\n",
    "\n",
    "#watch the original video\n",
    "video = conn.get_collection().get_video(video_id)\n",
    "video.player_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Scene Index 2024-07-22 07:52', 'scene_index_id': '5cbd6d6fb68a8baa', 'status': 'done'}, {'name': 'Scene Index 2024-07-22 08:39', 'scene_index_id': '7e5d8456aba295af', 'status': 'done'}, {'name': 'Scene Index 2024-07-22 09:02', 'scene_index_id': 'bf7802c6cbe5d3b1', 'status': 'done'}]\n"
     ]
    }
   ],
   "source": [
    "scene = video.list_scene_index()\n",
    "print(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new scene index\n",
    "from videodb import IndexType\n",
    "from videodb import SceneExtractionType\n",
    " \n",
    "index_id = video.index_scenes(\n",
    "    extraction_type=SceneExtractionType.time_based,\n",
    "    extraction_config={\"time\":10, \"select_frames\": ['first']},\n",
    "    prompt=\"all the actions taken by charchter in the frame\",\n",
    "    # callback_url=callback_url,\n",
    ")\n",
    "\n",
    "# Wait to Indexing to finish\n",
    "# scene_index = video.get_scene_index()\n",
    "# print(scene_index)\n",
    "\n",
    "# #Use existing scene index\n",
    "\n",
    "\n",
    "# scene_index = video.get_scene_index(\"bc32304c34e5e5a6\")\n",
    "# print(scene_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Scene Index 2024-07-22 07:52', 'scene_index_id': '5cbd6d6fb68a8baa', 'status': 'done'}, {'name': 'Scene Index 2024-07-22 08:39', 'scene_index_id': '7e5d8456aba295af', 'status': 'done'}, {'name': 'Scene Index 2024-07-22 09:02', 'scene_index_id': 'bf7802c6cbe5d3b1', 'status': 'done'}]\n"
     ]
    }
   ],
   "source": [
    "scene_index_id = video.list_scene_index()\n",
    "print(scene_index_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': 'In the frame, there is a character who appears to be performing the following actions:\\n\\n1. The character is partially visible, standing behind a doorway.\\n2. The character is shining a flashlight into the room or hallway, illuminating the space.\\n\\nThese actions suggest that the character could be searching for something or someone, or possibly investigating an area.', 'end': 10.0, 'start': 0.0}, {'description': 'The image shows a close-up of a cordless phone with an answering machine. No character is visible in the frame, so no actions taken by a character can be described.', 'end': 20.0, 'start': 10.0}, {'description': \"In this frame, the character is holding a phone up to their ear, indicating they are listening or speaking to someone on the phone. The person's expression suggests they may be deep in thought or concentration, but no other actions are clearly visible.\", 'end': 30.0, 'start': 20.0}, {'description': 'In the frame, the character is performing the following actions:\\n\\n1. Holding a phone to their ear.\\n2. Appearing to be listening intently or focusing on something.', 'end': 40.0, 'start': 30.0}, {'description': 'The image depicts an explosive scene inside a room, where furniture and debris are scattered, and a large fire is present. The following actions can be inferred from this frame:\\n\\n1. **Explosion Occurrence**: An explosion seems to have happened, causing debris and furniture to be propelled through the air.\\n2. **Fire Ignition**: The explosion has ignited a fire, as seen from the flames in the background.\\n3. **Debris Scattering**: Various objects, including parts of furniture, are scattered due to the force of the explosion.\\n4. **Shockwave Effect**: The blast likely created a shockwave, visible from the spread of particles and the knocked-over chairs.\\n\\nNo specific characters appear to be in the frame actively taking any actions at this moment.', 'end': 50.0, 'start': 40.0}, {'description': 'In this frame, the character, who is dressed in a white dress shirt, is performing the following actions:\\n\\n1. Standing or possibly leaning forward.\\n2. Raising their arms above their head.\\n3. Holding a stick or similar object with both hands, appearing to swing it downward.\\n\\nThe setting appears to be outdoors at night, with some buildings and flames in the background.', 'end': 60.0, 'start': 50.0}, {'description': 'In the frame provided, two characters are seen in the foreground. Here are their actions:\\n\\n1. The character on the left:\\n   - The individual is looking towards the television screen.\\n\\n2. The character on the right:\\n   - This individual is also looking towards the television screen. \\n\\nAdditionally, there is a television in the background displaying an individual standing with some objects visible, but no specific identifiable actions can be observed due to the blurred and distant view of the screen.', 'end': 70.0, 'start': 60.0}, {'description': \"I'm sorry, but based on the provided image, I cannot discern any characters or actions. The image primarily displays a dark and misty scene with bright light sources. If you could provide more context or a different image, I might be able to offer more assistance.\", 'end': 80.0, 'start': 70.0}, {'description': 'The frame depicts a scene with a person in the foreground. Here are all visible actions:\\n\\n1. The character appears to be wearing a respirator or a mask, suggesting they are in an environment that requires such protective gear.\\n2. The character is standing still, as there is no visible movement.\\n3. The character is facing a scene with flames and possibly debris in the background.\\n\\nThere is not enough detail to determine any additional specific actions that the character might be taking.', 'end': 90.0, 'start': 80.0}, {'description': 'In the frame, the character is:\\n\\n1. Walking down a brightly lit hallway.\\n2. Holding an object in each hand (though the objects are not clearly visible from this angle).', 'end': 100.0, 'start': 90.0}, {'description': 'In the given frame, the character is performing the following actions:\\n\\n1. Holding two guns, one in each hand.\\n2. Leaning or positioning himself against the wall.\\n3. Looking towards his left, indicating vigilance or awareness of something in that direction.', 'end': 110.0, 'start': 100.0}, {'description': 'The character in the frame is holding and pointing a firearm directly towards the camera or viewer.', 'end': 120.0, 'start': 110.0}, {'description': \"In the image, the character is taking the following actions:\\n\\n1. Standing in a doorway or an entrance.\\n2. Leaning slightly forward with hands extending down to either side.\\n\\nThe character's posture suggests they may be preparing to move or are looking down at something below their line of sight.\", 'end': 130.0, 'start': 120.0}, {'description': \"In the provided frame, the character appears to be falling or descending rapidly. The environment suggests that the character might be inside an elevator shaft or a narrow vertical space. The character's body posture and the motion blur indicate the downward movement.\", 'end': 140.0, 'start': 130.0}, {'description': \"In the frame, the character's actions are as follows:\\n\\n1. The character, who is seen from a close angle, is holding a grenade and attaching it to a door.\\n2. The character appears to be wearing black gloves and handling the grenade with care as they secure it.\\n3. The character completes the action, leaving the grenade primed and attached to the door.\", 'end': 150.0, 'start': 140.0}, {'description': 'In the frame, a character appears to be falling or crouching, with their body bent forward and head down. The character is dressed in tactical gear and a helmet. There is blood splatter visible on the wall behind them, indicating they may have been injured. Additionally, there is a bright flash to the side, possibly from an explosion or gunfire. The overall context suggests a violent or action scene.', 'end': 160.0, 'start': 150.0}, {'description': 'This image depicts an elevator button panel smeared with blood. Since the frame only shows the button panel and there are no visible characters or explicit actions taking place, it is impossible to infer any specific actions taken by characters within the scene based on this image alone. The presence of blood suggests some violent or distressing event may have occurred, but no explicit character actions are shown in the frame itself.', 'end': 170.0, 'start': 160.0}, {'description': 'In the image provided, there is no visible character, so no actions taken by a character can be observed.\\n\\nThe frame shows a panel displaying the numbers 1 through 6 and two arrows, likely part of an elevator control display, but no actions by a character are visible.', 'end': 180.0, 'start': 170.0}, {'description': \"In the frame provided, the character is taking the following actions:\\n\\n1. **Speaking**: The character's mouth is open, suggesting they are talking.\\n2. **Using a Mobile Phone**: The character is holding a mobile phone next to their ear, indicating they are on a phone call.\\n3. **Holding the Phone**: The character's right hand is gripping the phone.\\n\", 'end': 190.0, 'start': 180.0}, {'description': \"The character in the frame is standing still, facing forward, and looking slightly downward. His facial expression suggests he might be deep in thought or experiencing an intense emotion. He's wearing a white shirt and seems to be in a hallway, but no other specific actions are evident in this still image.\", 'end': 200.0, 'start': 190.0}, {'description': 'In the frame provided:\\n\\n1. The main character, with a shaved head and tattoo on the back of it, is standing in the foreground, facing away from the camera.\\n2. In the background, another character is running or lunging forward in the hallway.\\n3. The running character seems to be aiming at or chasing something or someone out of the frame.\\n\\nNote: The specific actions and context might be clearer if seen as part of the video, but based on this single frame, these are the discernible actions.', 'end': 210.0, 'start': 200.0}, {'description': 'In the frame provided, the character appears to be walking forward down a hallway or corridor. The character is moving with an intent focus straight ahead while wearing a white shirt. The setting is an elegant interior with chandeliers and wall sconces providing ambient lighting. No additional actions are visible in this specific frame.', 'end': 220.0, 'start': 210.0}, {'description': \"In the frame, the character is in the following actions:\\n\\n1. The character is positioned on a balcony or platform with a railing.\\n2. The character is wearing a suit and tie.\\n3. The character is leaning forward.\\n4. The character is wielding a handgun, pointing it downwards.\\n5. The character's facial expression appears to be concentrated or determined.\", 'end': 230.0, 'start': 220.0}, {'description': 'In the frame provided, the image is very dark, making it difficult to discern specific actions clearly. From what can be seen, there appears to be minimal discernible movement or actions by any characters. More context or frames with better visibility would be needed to accurately describe any actions taking place.', 'end': 240.0, 'start': 230.0}, {'description': \"In the frame, here's what the characters are doing:\\n\\n1. The character on the far left is holding an object near their face, possibly speaking into a communication device like a radio or phone.\\n2. The next character to the right is standing and looking forward, possibly keeping an eye on their surroundings.\\n3. The third character from the left appears to be adjusting their tie or collar.\\n4. The fourth character from the left is standing with hands visible, in conversation or observing the situation.\\n5. The fifth character, second from the right, is also standing and looking forward.\\n6. The character on the far right is standing with hands on their hips, possibly in a supervisory or authoritative stance.\\n\\nIn general, the characters seem to be in an indoor setting, possibly investigating or assessing a situation, with some of them engaging in conversation or using communication devices.\", 'end': 250.0, 'start': 240.0}, {'description': 'In the provided frame, there is a laptop with a screen displaying static and some text. Based on this frame, there are no visible characters present, thus no actions taken by any characters can be described. The focus is solely on the laptop with the static screen.', 'end': 260.0, 'start': 250.0}, {'description': 'In the frame provided, the following actions can be observed:\\n\\n1. The man on the left, who appears to be in a suit, seems to be standing or possibly engaging in conversation.\\n2. The man in the center, who appears to be in a military or police uniform, looks like he is speaking or shouting.\\n3. A character in the back is holding a weapon and appears to be performing a stand guard.\\n4. The character in the foreground, whose back is turned to the camera, appears to be approaching the group.\\n\\nIf there are any more nuanced details or additional actions taking place, they are not clearly visible in this specific frame.', 'end': 270.0, 'start': 260.0}, {'description': 'In the frame, the character appears to be:\\n\\n1. Standing, with a slight downward tilt of the head, suggesting a contemplative or focused expression.\\n2. Wearing a suit, indicating a formal or professional setting.\\n3. His face displays a serious or thoughtful demeanor.\\n4. There is an out-of-focus figure in the background, but the main character is not engaging or interacting with this figure in this particular frame.', 'end': 280.0, 'start': 270.0}, {'description': 'The image is a promotional frame asking viewers if they love \"JoBlo Movie Clips\" and encourages them to subscribe. The actions implied are:\\n\\n1. Love (indicated by the heart symbol) for JoBlo Movie Clips.\\n2. Subscription action, indicated by \"Subscribe Now!!\".\\n3. Noting that the content is updated daily from Monday to Friday.\\n\\nThe frame does not contain any characters taking actions; it is a static promotional image urging viewers to take action.', 'end': 290.0, 'start': 280.0}, {'description': 'The image does not display any characters or actions taken by characters. It is primarily textual and promotional in nature, containing the following elements:\\n\\n1. A question, \"DO YOU ❤️ JOBLO MOVIE CLIPS?\"\\n2. A call to action, \"SUBSCRIBE NOW!!\"\\n3. An instruction, \"CLICK ON THE BELL FOR THE LATEST NOTIFICATIONS!\"\\n4. A notice, \"UPDATED DAILY MONDAY TO FRIDAY\"\\n\\nThe image is promoting a movie clips channel (presumably on a video hosting platform) and encourages potential subscribers to click on a subscription button and a notification bell to receive updates on new content.', 'end': 298.32, 'start': 290.0}]\n"
     ]
    }
   ],
   "source": [
    "scene_index = video.get_scene_index(\"bf7802c6cbe5d3b1\")\n",
    "print(scene_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sendiing call to OPENAI \n",
      "        You are a video editor who uses AI. Given a user prompt and AI-generated scene descriptions of a video, analyze the descriptions to identify segments relevant to the user prompt for creating clips.\n",
      "\n",
      "        - **Instructions**: \n",
      "            - Evaluate the scene descriptions for relevance to the specified user prompt.\n",
      "            - Ensure that selected segments have clear start and end points, covering complete ideas or actions.\n",
      "            - Choose segments with the highest relevance and most comprehensive content.\n",
      "            - Optimize for engaging viewing experiences, considering visual appeal and narrative coherence.\n",
      "            - If closely related descriptions exist, combine them into a single, cohesive segment.\n",
      "            - Each selected segment should be substantial enough for a meaningful clip, typically covering at least 5 to 10 seconds of video content.\n",
      "\n",
      "            - User Prompts: Interpret prompts like 'find exciting moments' or 'identify key plot points' by matching keywords or themes in the scene descriptions to the intent of the prompt.\n",
      "        \n",
      "        Descriptions: [\"In the frame, there is a character who appears to be performing the following actions:\\n\\n1. The character is partially visible, standing behind a doorway.\\n2. The character is shining a flashlight into the room or hallway, illuminating the space.\\n\\nThese actions suggest that the character could be searching for something or someone, or possibly investigating an area.\", \"The image shows a close-up of a cordless phone with an answering machine. No character is visible in the frame, so no actions taken by a character can be described.\", \"In this frame, the character is holding a phone up to their ear, indicating they are listening or speaking to someone on the phone. The person's expression suggests they may be deep in thought or concentration, but no other actions are clearly visible.\", \"In the frame, the character is performing the following actions:\\n\\n1. Holding a phone to their ear.\\n2. Appearing to be listening intently or focusing on something.\", \"The image depicts an explosive scene inside a room, where furniture and debris are scattered, and a large fire is present. The following actions can be inferred from this frame:\\n\\n1. **Explosion Occurrence**: An explosion seems to have happened, causing debris and furniture to be propelled through the air.\\n2. **Fire Ignition**: The explosion has ignited a fire, as seen from the flames in the background.\\n3. **Debris Scattering**: Various objects, including parts of furniture, are scattered due to the force of the explosion.\\n4. **Shockwave Effect**: The blast likely created a shockwave, visible from the spread of particles and the knocked-over chairs.\\n\\nNo specific characters appear to be in the frame actively taking any actions at this moment.\", \"In this frame, the character, who is dressed in a white dress shirt, is performing the following actions:\\n\\n1. Standing or possibly leaning forward.\\n2. Raising their arms above their head.\\n3. Holding a stick or similar object with both hands, appearing to swing it downward.\\n\\nThe setting appears to be outdoors at night, with some buildings and flames in the background.\", \"In the frame provided, two characters are seen in the foreground. Here are their actions:\\n\\n1. The character on the left:\\n   - The individual is looking towards the television screen.\\n\\n2. The character on the right:\\n   - This individual is also looking towards the television screen. \\n\\nAdditionally, there is a television in the background displaying an individual standing with some objects visible, but no specific identifiable actions can be observed due to the blurred and distant view of the screen.\", \"I'm sorry, but based on the provided image, I cannot discern any characters or actions. The image primarily displays a dark and misty scene with bright light sources. If you could provide more context or a different image, I might be able to offer more assistance.\", \"The frame depicts a scene with a person in the foreground. Here are all visible actions:\\n\\n1. The character appears to be wearing a respirator or a mask, suggesting they are in an environment that requires such protective gear.\\n2. The character is standing still, as there is no visible movement.\\n3. The character is facing a scene with flames and possibly debris in the background.\\n\\nThere is not enough detail to determine any additional specific actions that the character might be taking.\", \"In the frame, the character is:\\n\\n1. Walking down a brightly lit hallway.\\n2. Holding an object in each hand (though the objects are not clearly visible from this angle).\", \"In the given frame, the character is performing the following actions:\\n\\n1. Holding two guns, one in each hand.\\n2. Leaning or positioning himself against the wall.\\n3. Looking towards his left, indicating vigilance or awareness of something in that direction.\", \"The character in the frame is holding and pointing a firearm directly towards the camera or viewer.\", \"In the image, the character is taking the following actions:\\n\\n1. Standing in a doorway or an entrance.\\n2. Leaning slightly forward with hands extending down to either side.\\n\\nThe character's posture suggests they may be preparing to move or are looking down at something below their line of sight.\", \"In the provided frame, the character appears to be falling or descending rapidly. The environment suggests that the character might be inside an elevator shaft or a narrow vertical space. The character's body posture and the motion blur indicate the downward movement.\", \"In the frame, the character's actions are as follows:\\n\\n1. The character, who is seen from a close angle, is holding a grenade and attaching it to a door.\\n2. The character appears to be wearing black gloves and handling the grenade with care as they secure it.\\n3. The character completes the action, leaving the grenade primed and attached to the door.\", \"In the frame, a character appears to be falling or crouching, with their body bent forward and head down. The character is dressed in tactical gear and a helmet. There is blood splatter visible on the wall behind them, indicating they may have been injured. Additionally, there is a bright flash to the side, possibly from an explosion or gunfire. The overall context suggests a violent or action scene.\", \"This image depicts an elevator button panel smeared with blood. Since the frame only shows the button panel and there are no visible characters or explicit actions taking place, it is impossible to infer any specific actions taken by characters within the scene based on this image alone. The presence of blood suggests some violent or distressing event may have occurred, but no explicit character actions are shown in the frame itself.\", \"In the image provided, there is no visible character, so no actions taken by a character can be observed.\\n\\nThe frame shows a panel displaying the numbers 1 through 6 and two arrows, likely part of an elevator control display, but no actions by a character are visible.\", \"In the frame provided, the character is taking the following actions:\\n\\n1. **Speaking**: The character's mouth is open, suggesting they are talking.\\n2. **Using a Mobile Phone**: The character is holding a mobile phone next to their ear, indicating they are on a phone call.\\n3. **Holding the Phone**: The character's right hand is gripping the phone.\\n\", \"The character in the frame is standing still, facing forward, and looking slightly downward. His facial expression suggests he might be deep in thought or experiencing an intense emotion. He's wearing a white shirt and seems to be in a hallway, but no other specific actions are evident in this still image.\"]\n",
      "        User Prompt: talking on phone\n",
      "        \n",
      "         **Output Format**: Return a JSON list named 'result' that containes the  fileds `sentence`, `start`, `end` Ensure the final output\n",
      "        strictly adheres to the JSON format specified without including additional text or explanations.         For the start and end use seconds as format\n",
      "        If there is no match return empty list without additional text. Use the following structure for your response:\n",
      "        {\"result\":{\"descriptions\":<>, \"start\":<>, \"end\":<>}}\n",
      "        \n",
      "{'id': 'chatcmpl-9npUPiWGSwvxCqOxAG8qJPmXuJXMU', 'object': 'chat.completion', 'created': 1721663025, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"result\": [\\n    {\\n        \"descriptions\": \"In this frame, the character is holding a phone up to their ear, indicating they are listening or speaking to someone on the phone. The person\\'s expression suggests they may be deep in thought or concentration, but no other actions are clearly visible.\", \\n        \"start\": 20, \\n        \"end\": 30\\n    }, \\n    {\\n        \"descriptions\": \"In the frame, the character is performing the following actions:\\\\n\\\\n1. Holding a phone to their ear.\\\\n2. Appearing to be listening intently or focusing on something.\", \\n        \"start\": 35, \\n        \"end\": 45\\n    }, \\n    {\\n        \"descriptions\": \"In the frame provided, the character is taking the following actions:\\\\n\\\\n1. **Speaking**: The character\\'s mouth is open, suggesting they are talking.\\\\n2. **Using a Mobile Phone**: The character is holding a mobile phone next to their ear, indicating they are on a phone call.\\\\n3. **Holding the Phone**: The character\\'s right hand is gripping the phone.\",\\n        \"start\": 150,\\n        \"end\": 160\\n    }\\n]}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1694, 'completion_tokens': 250, 'total_tokens': 1944}, 'system_fingerprint': None}\n",
      "Sendiing call to OPENAI \n",
      "        You are a video editor who uses AI. Given a user prompt and AI-generated scene descriptions of a video, analyze the descriptions to identify segments relevant to the user prompt for creating clips.\n",
      "\n",
      "        - **Instructions**: \n",
      "            - Evaluate the scene descriptions for relevance to the specified user prompt.\n",
      "            - Ensure that selected segments have clear start and end points, covering complete ideas or actions.\n",
      "            - Choose segments with the highest relevance and most comprehensive content.\n",
      "            - Optimize for engaging viewing experiences, considering visual appeal and narrative coherence.\n",
      "            - If closely related descriptions exist, combine them into a single, cohesive segment.\n",
      "            - Each selected segment should be substantial enough for a meaningful clip, typically covering at least 5 to 10 seconds of video content.\n",
      "\n",
      "            - User Prompts: Interpret prompts like 'find exciting moments' or 'identify key plot points' by matching keywords or themes in the scene descriptions to the intent of the prompt.\n",
      "        \n",
      "        Descriptions: [\"In the frame provided:\\n\\n1. The main character, with a shaved head and tattoo on the back of it, is standing in the foreground, facing away from the camera.\\n2. In the background, another character is running or lunging forward in the hallway.\\n3. The running character seems to be aiming at or chasing something or someone out of the frame.\\n\\nNote: The specific actions and context might be clearer if seen as part of the video, but based on this single frame, these are the discernible actions.\", \"In the frame provided, the character appears to be walking forward down a hallway or corridor. The character is moving with an intent focus straight ahead while wearing a white shirt. The setting is an elegant interior with chandeliers and wall sconces providing ambient lighting. No additional actions are visible in this specific frame.\", \"In the frame, the character is in the following actions:\\n\\n1. The character is positioned on a balcony or platform with a railing.\\n2. The character is wearing a suit and tie.\\n3. The character is leaning forward.\\n4. The character is wielding a handgun, pointing it downwards.\\n5. The character's facial expression appears to be concentrated or determined.\", \"In the frame provided, the image is very dark, making it difficult to discern specific actions clearly. From what can be seen, there appears to be minimal discernible movement or actions by any characters. More context or frames with better visibility would be needed to accurately describe any actions taking place.\", \"In the frame, here's what the characters are doing:\\n\\n1. The character on the far left is holding an object near their face, possibly speaking into a communication device like a radio or phone.\\n2. The next character to the right is standing and looking forward, possibly keeping an eye on their surroundings.\\n3. The third character from the left appears to be adjusting their tie or collar.\\n4. The fourth character from the left is standing with hands visible, in conversation or observing the situation.\\n5. The fifth character, second from the right, is also standing and looking forward.\\n6. The character on the far right is standing with hands on their hips, possibly in a supervisory or authoritative stance.\\n\\nIn general, the characters seem to be in an indoor setting, possibly investigating or assessing a situation, with some of them engaging in conversation or using communication devices.\", \"In the provided frame, there is a laptop with a screen displaying static and some text. Based on this frame, there are no visible characters present, thus no actions taken by any characters can be described. The focus is solely on the laptop with the static screen.\", \"In the frame provided, the following actions can be observed:\\n\\n1. The man on the left, who appears to be in a suit, seems to be standing or possibly engaging in conversation.\\n2. The man in the center, who appears to be in a military or police uniform, looks like he is speaking or shouting.\\n3. A character in the back is holding a weapon and appears to be performing a stand guard.\\n4. The character in the foreground, whose back is turned to the camera, appears to be approaching the group.\\n\\nIf there are any more nuanced details or additional actions taking place, they are not clearly visible in this specific frame.\", \"In the frame, the character appears to be:\\n\\n1. Standing, with a slight downward tilt of the head, suggesting a contemplative or focused expression.\\n2. Wearing a suit, indicating a formal or professional setting.\\n3. His face displays a serious or thoughtful demeanor.\\n4. There is an out-of-focus figure in the background, but the main character is not engaging or interacting with this figure in this particular frame.\", \"The image is a promotional frame asking viewers if they love \\\"JoBlo Movie Clips\\\" and encourages them to subscribe. The actions implied are:\\n\\n1. Love (indicated by the heart symbol) for JoBlo Movie Clips.\\n2. Subscription action, indicated by \\\"Subscribe Now!!\\\".\\n3. Noting that the content is updated daily from Monday to Friday.\\n\\nThe frame does not contain any characters taking actions; it is a static promotional image urging viewers to take action.\", \"The image does not display any characters or actions taken by characters. It is primarily textual and promotional in nature, containing the following elements:\\n\\n1. A question, \\\"DO YOU \\u2764\\ufe0f JOBLO MOVIE CLIPS?\\\"\\n2. A call to action, \\\"SUBSCRIBE NOW!!\\\"\\n3. An instruction, \\\"CLICK ON THE BELL FOR THE LATEST NOTIFICATIONS!\\\"\\n4. A notice, \\\"UPDATED DAILY MONDAY TO FRIDAY\\\"\\n\\nThe image is promoting a movie clips channel (presumably on a video hosting platform) and encourages potential subscribers to click on a subscription button and a notification bell to receive updates on new content.\"]\n",
      "        User Prompt: talking on phone\n",
      "        \n",
      "         **Output Format**: Return a JSON list named 'result' that containes the  fileds `sentence`, `start`, `end` Ensure the final output\n",
      "        strictly adheres to the JSON format specified without including additional text or explanations.         For the start and end use seconds as format\n",
      "        If there is no match return empty list without additional text. Use the following structure for your response:\n",
      "        {\"result\":{\"descriptions\":<>, \"start\":<>, \"end\":<>}}\n",
      "        \n",
      "{'id': 'chatcmpl-9npUcHZRHP0D3pji9mBvZwgiirRY2', 'object': 'chat.completion', 'created': 1721663038, 'model': 'gpt-4-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\"result\":[]}'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 1343, 'completion_tokens': 4, 'total_tokens': 1347}, 'system_fingerprint': None}\n",
      "[{'result': [{'descriptions': \"In this frame, the character is holding a phone up to their ear, indicating they are listening or speaking to someone on the phone. The person's expression suggests they may be deep in thought or concentration, but no other actions are clearly visible.\", 'start': 20, 'end': 30}, {'descriptions': 'In the frame, the character is performing the following actions:\\n\\n1. Holding a phone to their ear.\\n2. Appearing to be listening intently or focusing on something.', 'start': 35, 'end': 45}, {'descriptions': \"In the frame provided, the character is taking the following actions:\\n\\n1. **Speaking**: The character's mouth is open, suggesting they are talking.\\n2. **Using a Mobile Phone**: The character is holding a mobile phone next to their ear, indicating they are on a phone call.\\n3. **Holding the Phone**: The character's right hand is gripping the phone.\", 'start': 150, 'end': 160}]}, {'result': []}]\n"
     ]
    }
   ],
   "source": [
    "from video_prompter import scene_prompter\n",
    "\n",
    "\n",
    "# scene_index = video.get_scene_index(index_id)\n",
    "#Choose a prompt to create create clip. \n",
    "# user_prompt = \"all the gun shots fired\"\n",
    "# user_prompt = \"standing behind a doorway\"\n",
    "user_prompt = \"talking on phone\"\n",
    "result = scene_prompter(scene_index, user_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResult(collection_id=c-50e11372-632c-40b0-8aa7-c055d8d89b8d, stream_url=None, player_url=None, shots=[Shot(video_id=m-2c2b792f-424c-432b-bcbe-9e3c7e00dcbf, video_title=None, start=185.0, end=186.0, text=The character in the frame is engaged in several actions:\n",
      "\n",
      "1. The character is talking on a phone, bringing it close to their ear and mouth.\n",
      "2. The character appears to be seated in an office chair.\n",
      "3. The character seems to have raised their left hand towards their face.\n",
      "\n",
      "The setting indicates motion, potentially suggesting urgency or a tense situation. There may also be a dynamic light source, suggesting an active environment., search_score=0.639981508, stream_url=None, player_url=None)])\n",
      "1 length mat\n",
      "185.0 186.0\n",
      "SearchResult(collection_id=c-50e11372-632c-40b0-8aa7-c055d8d89b8d, stream_url=None, player_url=None, shots=[Shot(video_id=m-2c2b792f-424c-432b-bcbe-9e3c7e00dcbf, video_title=None, start=220.0, end=230.0, text=In the frame, the character is in the following actions:\n",
      "\n",
      "1. The character is positioned on a balcony or platform with a railing.\n",
      "2. The character is wearing a suit and tie.\n",
      "3. The character is leaning forward.\n",
      "4. The character is wielding a handgun, pointing it downwards.\n",
      "5. The character's facial expression appears to be concentrated or determined., search_score=0.746336222, stream_url=None, player_url=None)])\n",
      "1 length mat\n",
      "220.0 230.0\n"
     ]
    }
   ],
   "source": [
    "# search matching video segments and watch the stream\n",
    "from videodb import SearchType\n",
    "from videodb import IndexType\n",
    "from videodb.asset import VideoAsset, AudioAsset, ImageAsset\n",
    "from videodb.timeline import Timeline\n",
    "# from videodb.asset import TextAsset, TextStyle\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "for description in result:\n",
    "    search_res = video.search(description, index_type =IndexType.scene)\n",
    "    print(search_res)\n",
    "    matched_segments = search_res.get_shots()\n",
    "    print(len(matched_segments),\"length mat\")\n",
    "    #no exact match found.\n",
    "    if len(matched_segments) == 0:\n",
    "        continue\n",
    "\n",
    "    #video segment\n",
    "    video_shot = matched_segments[0]\n",
    "\n",
    "    print(video_shot.start,video_shot.end )\n",
    "\n",
    "    #Create a new Video Asset and add it to a timeline.\n",
    "    timeline.add_inline(VideoAsset(asset_id=video.id, start=video_shot.start, end=video_shot.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stream.videodb.io/v3/published/manifests/c9bc9f26-9649-4828-b5ac-5a20b9fa15c8.m3u8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/c9bc9f26-9649-4828-b5ac-5a20b9fa15c8.m3u8'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = timeline.generate_stream()\n",
    "print(stream)\n",
    "play_stream(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "\n",
    "\n",
    "def construct_timeline_and_stream( selected_frames):\n",
    "    timeline = Timeline(conn)\n",
    "    \n",
    "    print(\"Selected frames:\", selected_frames)  \n",
    "\n",
    "    for frame in selected_frames:\n",
    "        print(\"Adding frame:\", frame)  \n",
    "        video_asset = VideoAsset(\n",
    "            asset_id=video_id,\n",
    "            start=frame['start_time'],\n",
    "            end=frame['end_time']\n",
    "        )\n",
    "        timeline.add_inline(video_asset)\n",
    "    \n",
    "    print(\"Timeline created:\", timeline)  \n",
    "    \n",
    "    stream_url = timeline.generate_stream()\n",
    "    print(\"Stream URL:\", stream_url)\n",
    "    return play_stream(stream_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted timeframe: start=20, end=30\n",
      "Extracted timeframe: start=35, end=45\n",
      "Extracted timeframe: start=150, end=160\n",
      "Appending: {'start_time': 35, 'end_time': 45}\n",
      "Appending: {'start_time': 150, 'end_time': 160}\n",
      "Selected frames: [{'start_time': 20, 'end_time': 30}, {'start_time': 35, 'end_time': 45}, {'start_time': 150, 'end_time': 160}]\n",
      "Adding frame: {'start_time': 20, 'end_time': 30}\n",
      "Adding frame: {'start_time': 35, 'end_time': 45}\n",
      "Adding frame: {'start_time': 150, 'end_time': 160}\n",
      "Timeline created: <videodb.timeline.Timeline object at 0x109150970>\n",
      "Stream URL: https://stream.videodb.io/v3/published/manifests/aa863872-ed64-4425-9c05-4a2d49902a60.m3u8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/aa863872-ed64-4425-9c05-4a2d49902a60.m3u8'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from video_prompter import extract_timestamps,merge_timeframes\n",
    "from videodb.timeline import Timeline\n",
    "\n",
    "\n",
    "timeframes = extract_timestamps(result)\n",
    "merged_timeframes = merge_timeframes(timeframes)\n",
    "construct_timeline_and_stream(merged_timeframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stream.videodb.io/v3/published/manifests/e6a005de-e685-47f8-8ad0-a1a1206d55e7.m3u8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://console.videodb.io/player?url=https://stream.videodb.io/v3/published/manifests/e6a005de-e685-47f8-8ad0-a1a1206d55e7.m3u8'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = timeline.generate_stream()\n",
    "print(stream)\n",
    "play_stream(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
